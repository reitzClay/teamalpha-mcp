#!/usr/bin/env python3
"""
LM Studio Quick Start for TeamAlpha

One-command setup to connect your fleet agents to LM Studio.
"""

import os
import sys
import subprocess
from pathlib import Path


def print_banner():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  TeamAlpha + LM Studio Integration                         â•‘
â•‘                     Connect Your Agent Fleet to LM Studio                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)


def check_lmstudio():
    """Check if LM Studio is running."""
    print("ğŸ” Checking for LM Studio...")
    
    try:
        import requests
        response = requests.get("http://10.5.0.2:1234/health", timeout=2)
        if response.ok:
            print("âœ… LM Studio is running on http://10.5.0.2:1234")
            return True
    except:
        pass
    
    print("âŒ LM Studio not found")
    print("\nğŸ“‹ To use LM Studio with TeamAlpha:")
    print("   1. Start LM Studio on Windows")
    print("   2. Load model: gpt-oss-20b-GGUF")
    print("   3. Run this script again")
    return False


def list_lmstudio_models():
    """List models available in LM Studio."""
    try:
        import requests
        response = requests.get("http://10.5.0.2:1234/v1/models", timeout=5)
        if response.ok:
            models = response.json().get("data", [])
            if models:
                print("\nğŸ“¦ Loaded models:")
                for model in models:
                    print(f"   â€¢ {model.get('id', 'unknown')}")
                return models
    except:
        pass
    
    print("\nâš ï¸  No models loaded in LM Studio")
    print("   Load gpt-oss-20b-GGUF in LM Studio to continue")
    return []


def setup_environment():
    """Setup environment variables."""
    print("\nğŸ”§ Setting environment for LM Studio...")
    
    os.environ["LLM_PROVIDER"] = "lmstudio"
    os.environ["LMSTUDIO_HOST"] = "http://10.5.0.2:1234"
    
    print("âœ… Environment configured:")
    print(f"   LLM_PROVIDER={os.environ['LLM_PROVIDER']}")
    print(f"   LMSTUDIO_HOST={os.environ['LMSTUDIO_HOST']}")


def test_connection():
    """Test agent connection to LM Studio."""
    print("\nğŸ§ª Testing agent connection...")
    
    sys.path.insert(0, str(Path(__file__).parent))
    
    try:
        from src.teamalpha.agent import Agent, AgentRole
        
        # Set environment
        os.environ["LLM_PROVIDER"] = "lmstudio"
        
        # Create test agent
        print("   Creating test agent...")
        agent = Agent(
            name="TestAlice",
            role=AgentRole.ENGINEER,
            provider="lmstudio"
        )
        print(f"   âœ… Agent created: {agent}")
        
        # Quick test
        print("   Sending test prompt...")
        response = agent.think("What is AI? Answer in one sentence.")
        
        if response and len(response) > 10:
            print("âœ… Connection successful!")
            print(f"\nğŸ“ Sample output:\n{response[:150]}...\n")
            return True
        else:
            print("âŒ Empty response from agent")
            return False
    
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False


def start_interactive_client():
    """Start the interactive client with LM Studio."""
    print("\nğŸš€ Starting interactive client with LM Studio...\n")
    
    # Set environment
    os.environ["LLM_PROVIDER"] = "lmstudio"
    os.environ["LMSTUDIO_HOST"] = "http://10.5.0.2:1234"
    
    # Run client
    script_path = Path(__file__).parent / "interactive_client.py"
    venv_python = Path(__file__).parent / ".venv" / "bin" / "python3"
    
    if venv_python.exists():
        subprocess.run([str(venv_python), str(script_path)])
    else:
        subprocess.run([sys.executable, str(script_path)])


def main():
    """Main setup routine."""
    print_banner()
    
    # Check LM Studio
    if not check_lmstudio():
        print("\nğŸ’¡ Next steps:")
        print("   1. Start LM Studio")
        print("   2. Load gpt-oss-20b-GGUF model")
        print("   3. Run: python3 setup_lmstudio.py")
        sys.exit(1)
    
    # List models
    models = list_lmstudio_models()
    if not models:
        print("\nğŸ’¡ Next steps:")
        print("   1. Load a model in LM Studio (gpt-oss-20b-GGUF recommended)")
        print("   2. Run: python3 setup_lmstudio.py")
        sys.exit(1)
    
    # Setup environment
    setup_environment()
    
    # Test connection
    if not test_connection():
        print("âŒ Connection test failed")
        sys.exit(1)
    
    # Start client
    print("\n" + "=" * 76)
    print("âœ… LM Studio is ready! Starting interactive client...")
    print("=" * 76)
    
    response = input("\nStart interactive client? (y/n): ")
    if response.lower() == "y":
        start_interactive_client()
    else:
        print("\nğŸ’¡ To start later, run:")
        print("   LMSTUDIO_HOST=http://10.5.0.2:1234 LLM_PROVIDER=lmstudio ./run-client.sh")


if __name__ == "__main__":
    main()
